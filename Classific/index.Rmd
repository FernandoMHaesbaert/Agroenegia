---
title: "Disciplina de An√°lise de Dados no Agroneg√≥cio"
author: "Prof. Dr. Fernando Machado Haesbaert"
output: 
      prettydoc::html_pretty:
        theme: architect
        highlight: github
---

```{r klippy, echo=FALSE, include=TRUE}
#install.packages("remotes")
#remotes::install_github("rlesur/klippy", force = TRUE)
library(klippy)
klippy::klippy(
  lang = c("r", "markdown"),
  all_precode = FALSE,
  position = c("top", "right"),
  color = "auto",
  tooltip_message = "Copy code",
  tooltip_success = "Copied!"
)
```


# Algoritmo de Classifica√ß√£o - KNN
## Introdu√ß√£o
Nesta aula veremos alguns algoritmos de classifica√ß√£o, come√ßando com o `K-Nearest Neighbors (KNN)`, que √© um algoritmo de aprendizado supervisionado. O KNN √© um algoritmo simples que armazena todos os casos dispon√≠veis e classifica novos casos com base em uma medida de similaridade (por exemplo, dist√¢ncia Euclidiana). O KNN tem sido usado em estat√≠stica e reconhecimento de padr√µes por muitos anos.  

As t√©cnicas de classifica√ß√£o s√£o utilizadas para a identifica√ß√£o do r√≥tulo de determinadas observa√ß√µes com base em caracter√≠sticas e informa√ß√µes previamente conhecidas (Lantz 2013).  A classifica√ß√£o √© uma t√©cnica de aprendizado supervisionado, onde o objetivo √© identificar a qual classe pertence uma determinada observa√ß√£o.  

A capacidade do modelo de gerar uma predi√ß√£o satisfat√≥ria √© denominada capacidade de generaliza√ß√£o, ou seja, qu√£o bom o modelo √© na predi√ß√£o de classe ou valor dos novos registros ainda n√£o rotulados.  

Neste tutorial exploramento os algoritmos `K vizinhos mais pr√≥ximos (K Nearest Neighbor - KNN)`, `Na√Øve Bayes` e `√Årvore de Decis√£o`.  
  
### Objetivos
1. Apresentar o algoritmo KNN;
2. Apresentar o algoritmo Na√Øve Bayes;
3. Apresentar o algoritmo √Årvore de Decis√£o.

### Pr√©-requisitos

Para acompanhar este tutorial √© necess√°rio ter conhecimento b√°sico de R e de estat√≠stica descritiva.  

## Algortimo KNN

O algoritmo KNN √© um dos algoritmos mais simples de classifica√ß√£o e √© baseado na ideia de que os objetos semelhantes tendem a estar pr√≥ximos uns dos outros. O algoritmo KNN √© um tipo de aprendizado supervisionado, onde o resultado √© classificado por maioria de votos dos vizinhos mais pr√≥ximos.   

O algoritmo K-Nearest Neighbors (KNN) √© um dos m√©todos cl√°ssicos de classifica√ß√£o, conhecido por sua simplicidade e efici√™ncia. Ele √© amplamente utilizado para classificar objetos com base em exemplos de treinamento que est√£o mais pr√≥ximos no espa√ßo de caracter√≠sticas, ou seja, ele toma como base a proximidade entre pontos de dados para inferir a classe de novos exemplos.  

Para seu funcionamento, o KNN necessita inicialmente de uma m√©trica de dist√¢ncia que permita calcular o qu√£o pr√≥ximos dois exemplos est√£o um do outro. A m√©trica mais comum utilizada √© a `dist√¢ncia Euclidiana`, mas outras m√©tricas, como a `dist√¢ncia de Manhattan` ou `de Minkowski`, tamb√©m podem ser aplicadas, dependendo da natureza dos dados.  

Outro passo importante no uso do KNN √© a defini√ß√£o do valor de `K`, que indica quantos vizinhos mais pr√≥ximos ser√£o considerados pelo algoritmo na classifica√ß√£o. A escolha de K √© crucial, pois um valor muito pequeno pode tornar o modelo sens√≠vel a ru√≠dos, enquanto um valor muito grande pode diluir a influ√™ncia dos vizinhos mais relevantes.  

Finalmente, a classifica√ß√£o de um exemplo desconhecido √© feita por meio de uma vota√ß√£o majorit√°ria entre os K vizinhos mais pr√≥ximos. Ou seja, o r√≥tulo de classe que for mais frequente entre os vizinhos pr√≥ximos ser√° atribu√≠do ao exemplo a ser classificado. Este processo simples e intuitivo faz do KNN uma escolha comum em problemas de classifica√ß√£o, especialmente quando a interpreta√ß√£o da decis√£o √© importante.  

```{r}
# Setar diret√≥rio de Trabalho
setwd("C:/Users/fhaes/Documents/GitHub/Agroenegia/Classific")
```


![](images/knn_imagem.png)
  
A imagem acima ilustra o funcionamento do algoritmo KNN. Neste exemplo, temos um conjunto de dados com duas classes distintas (amarelo e roxo) e um novo exemplo a ser classificado (ponto vermelho). O algoritmo KNN calcula a dist√¢ncia entre o novo exemplo e os exemplos de treinamento, selecionando os K vizinhos mais pr√≥ximos. Neste caso, K = 3, ent√£o os tr√™s vizinhos mais pr√≥ximos s√£o selecionados (dois da classe roxo e um da classe amarelo). Como a maioria dos vizinhos √© da classe roxo, o novo exemplo √© classificado como roxo. Para o  K = 6, o novo exemplo seria classificado como amarelo, pois s√£o quatro amarelos e dois roxos.  

### Vantagens e Desvantagens do KNN

#### Vantagens
1. **Simplicidade**: O KNN √© um algoritmo simples e f√°cil de entender, o que o torna uma boa escolha para problemas de classifica√ß√£o.
2. **N√£o param√©trico**: O KNN n√£o faz suposi√ß√µes sobre a distribui√ß√£o dos dados, o que o torna √∫til para dados n√£o lineares e complexos.
3. **Interpretabilidade**: A classifica√ß√£o do KNN √© baseada na proximidade dos exemplos, o que torna f√°cil interpretar as decis√µes do modelo.
4. **Robustez**: O KNN √© robusto a outliers e ru√≠dos nos dados, pois considera v√°rios vizinhos pr√≥ximos em vez de depender de um √∫nico exemplo.

#### Desvantagens
1. **Sensibilidade √† escala**: O KNN √© sens√≠vel √† escala dos dados, o que pode levar a resultados distorcidos se as vari√°veis tiverem escalas diferentes.
2. **Custo computacional**: O KNN precisa calcular a dist√¢ncia entre o novo exemplo e todos os exemplos de treinamento, o que pode ser computacionalmente caro para grandes conjuntos de dados.
3. **Escolha de K**: A escolha do valor de K √© crucial para o desempenho do modelo, e um valor inadequado pode levar a resultados sub√≥timos.



### Exemplo de Aplica√ß√£o do KNN

Primeiro vamos carregar os pacotes que iremos utlizar:

#### Pacotes

Para isso vamos carregar os seguintes pacotes:  
```{r, message=FALSE, warning=FALSE}
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(skimr)) install.packages("skimr")
if(!require(caret)) install.packages("caret")
if(!require(philentropy)) install.packages("philentropy")
if(!require(readxl)) install.packages("readxl")
if(!require(class)) install.packages("class")
if(!require(gt)) install.packages("gt")

library(tidyverse)
library(skimr)
library(caret)
library(philentropy)
library(readxl)
library(class)
library(gt)
```



```{r}
dados <- tibble(
  a1 = c(0,10,2,6,4,1,8,10,6),
  a2 = c(250,150,90,78,20,170,160,180, 200),
  a3 = c(36,34,10,8,1,70,41,38,45))

classe <- factor(c(rep(c("A", "B"), 4), NA))
dados <- cbind(dados, classe)
```

Vamos visualizar os dados:  
```{r echo=FALSE}
dados |> 
      gt()
```

#### Padronizar os dados

A padroniza√ß√£o dos dados √© uma etapa importante para garantir que todas as vari√°veis tenham a mesma escala e n√£o influenciem indevidamente o algoritmo.  

O c√°lculo do valor padronizado √© feito subtraindo a m√©dia da vari√°vel e dividindo pelo desvio padr√£o:  
$$x^* = \frac{x_i - \bar x}{s} $$
Onde o $x^*$ √© o valor padronizado, $x_i$ √© o valor original, $\bar x$ √© a m√©dia da vari√°vel e $s$ √© o desvio padr√£o.  
Para isso, vamos padronizar os dados utilizando a fun√ß√£o `scale()` do R.

```{r}
# Padronizando
df <- scale(dados[,1:3], 
            center = T)
```

Vamos visualizar os dados padronizados:  
```{r echo=FALSE}
df |> 
  as_tibble() |> 
  gt()
```



### Calculando a dist√¢ncia entre dois pontos.  
Existem v√°rias formas diferentes de calcular essa dist√¢ncia. A mais simples √© a dist√¢ncia euclidiana. √â a dist√¢ncia entre pontos, que pode ser provada pela aplica√ß√£o repetida do teorema de Pit√°goras.  

A dist√¢ncia euclidiana entre dois pontos, `p` e `q`, em um espa√ßo n-dimensional √© calculada da seguinte forma:  

$$d(p, q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \ldots + (p_n - q_n)^2}$$

Onde:
- $p_1, p_2, \ldots, p_n$ s√£o as coordenadas do ponto `p`;
- $q_1, q_2, \ldots, q_n$ s√£o as coordenadas do ponto `q`;
- $n$ √© o n√∫mero de dimens√µes do espa√ßo.


Essencialmente, a dist√¢ncia Euclidiana √© a raiz quadrada da soma dos quadrados das diferen√ßas entre as coordenadas correspondentes de ùëù e ùëû.

Vamos calcular a dist√¢ncia entre os pontos:  
```{r, warning=FALSE, message=FALSE}
distancias <- philentropy::distance(x = df,
                              method = "euclidean") |> 
  round(digits = 3)
print(distancias)
```

Observe que o resultado √© uma matriz de dist√¢ncias entre os pontos. Cada elemento da matriz representa a dist√¢ncia entre os pontos correspondentes nas linhas e colunas. Para o nosso exemplo em estudo, o elemento na linha 9 √© o que desejamos verificar as dist√¢ncias. 

Desta forma, a dist√¢ncia entre o ponto 9 e os demais pontos √© observada na √∫ltima linha da matriz. Sendo a dist√¢ncia do ponto 9 para o ponto 1 de `r distancias[9,1]`, para o ponto 2 de `r distancias[9,2]`, para o ponto 3 de `r distancias[9,3]`, para o ponto 4 de `r distancias[9,4]`, para o ponto 5 de `r distancias[9,5]`, para o ponto 6 de `r distancias[9,6]`, para o ponto 7 de `r distancias[9,7]` e para o ponto 8 de `r distancias[9,8]`.  

Outra fun√ß√£o que pode ser utilizada para calcular a dist√¢ncia entre os pontos √© a fun√ß√£o `dist()` do pacote {stats} R.  

```{r}
dist2 <- dist(df, method = "euclidean") |> 
  round(digits = 3)
print(dist2)
```

O resultado √© a dist√¢ncia entre os pontos, de forma semelhante a fun√ß√£o `philentropy::distance()`.

### Classifica√ß√£o do ponto 9

Vamos classificar o ponto 9 utilizando a l√≥gica por tr√°s do algoritmo KNN. Para isso, vamos considerar inicialmente os 3 vizinhos mais pr√≥ximos (`k = 3`).  E por vota√ß√£o majorit√°ria atribui-se √† amostra desconhecida a classe mais frequente entre os K vizinhos. Cada vizinho vota com a sua classe, e a classe com mais votos √© atribu√≠da ao novo ponto. Por isso a import√¢ncia de escolher um valor de K √≠mpar.  

Voltando a nossa base de dados originais.  

```{r}
dados
```

Vamos analisar as dist√¢ncias do ponto 9 para os demais pontos em ordem crescente.
```{r}
d9 <- distancias[9,] |> 
  sort()
print(d9)
```

Agora vamos considerar os 3 vizinhos mais pr√≥ximos para o ponto 9. Que s√£o os pontos 7 (dist√¢ncia de `r distancias[9,7]`), 8 (dist√¢ncia de `r distancias[9,8]`) e 2 (dist√¢ncia de `r distancias[9,2]`). Agora obervando a classe desses pontos, temos que a classe do ponto 7 √© $A$, do ponto 8 √© $B$ e do ponto 2 √© $B$, sendo a classe mais frequente a classe `B`. Portando, o ponto 9 √© classificado como $B$.  
 
Se quisermos classificar o ponto 9 para um valor de $K = 5$, temos que os pontos mais pr√≥ximos s√£o os pontos 7, 8, 2, 1 e 6. E a classe mais frequente √© a classe $B$. Portanto, o ponto 9 √© classificado como $B$ tamb√©m para k = 5.  

Para $k = 7$, temos que os pontos mais pr√≥ximos s√£o os pontos 7, 8, 2, 1, 6, 4 e 3. E a classe mais frequente √© a classe $B$. Portanto, o ponto 9 √© classificado como $B$ para k = 7.


### Implementa√ß√£o do KNN

Para isso, vamos utilizar a fun√ß√£o `knn()` do pacote {class} R.  

Como √© um exemplo simples, n√£o dividimos em treino e teste, no entanto o equivalente a nossos conjunto de dados teste s√£o os oito primeiros pontos e o ponto 9 √© o ponto a ser classificado.  

```{r}
treino <- df[1:8,]
classe <- dados[1:8,4]
prever <- df[9,1:3] # Elemento da linha 9
```

Agora vamos classificar o ponto 9 para $k = 3$ utilizando a fun√ß√£o `knn()` do pacote {class} R.  

```{r}
previs√£o <- knn(treino, 
                prever, 
                cl = classe, 
                k = 3)
print(previs√£o)
```

Observamos que a previs√£o para o ponto 9 √© a classe $B$.

Mudando o valor do hiperpar√¢metro $k$ para 5 e 7, temos:  

```{r}
previs√£o <- knn(treino, 
                prever, 
                cl = classe, 
                k = 5)
print(previs√£o)
```

A classifica√ß√£o do ponto 9 para $k = 5$ √© a classe $B$. E para $k = 7$ temos:  

```{r}
previs√£o <- knn(treino, 
                prever, 
                cl = classe, 
                k = 7)
print(previs√£o)
```

Para os tr√™s valores de $k$ testados, a classifica√ß√£o do ponto 9 foi a classe $B$. Podemos concluir que o ponto 9 foi classificado como $B$ para os valores de $k = 3$, $k = 5$ e $k = 7$, sendo razo√°vel aceitas esta classifica√ß√£o.  





### Exemplo 2 de Aplica√ß√£o do KNN
Vejamos outro exemplo de aplica√ß√£o do KNN.  

O exemplo a seguir √© um exemplo de classifica√ß√£o de sementes de soja.  

```{r}
# Vamos limpar a mem√≥ria
rm(list = ls())
```

Carregando os dados
```{r}
# Classes de sementes de soja
df <- read_excel("exemplo_semente.xlsx")
glimpse(df)
```

```{r}
# Transformar a classe em fator na sequ√™cia: Alta, M√©dia e Baixa. 
df$Classe <- factor(df$Classe, 
                    levels = c("alta", "media", "baixa"))
print(df$Classe)
```


Vamos visualizar os dados:  
```{r}
plot(df[,1:5])
```

A fun√ß√£o skimr::skim() √© uma fun√ß√£o que fornece um resumo estat√≠stico dos dados.  
```{r}
# Verifica√ß√£o de escala.
skimr::skim(df)
```

Podendo ser realizada por categoria.
```{r}
# Resumo por Classe
df |> 
      group_by(Classe) |>
      skim()
```


Outra forma de visualizar os dados √© atrav√©s de uma tabela de frequ√™ncia.  
```{r}
casses_verdadeiras <- xtabs(~Classe, data = df)
print(casses_verdadeiras)
```

Vamos padronizar os dados.  
```{r}
# Padronizando
df_p <- data.frame(scale(df[,1:5]), 
                   as.factor(df$Classe)) |> 
  rename(Classe = as.factor.df.Classe.)
print(summary(df_p))
```

Observe que os valores foram padronizados, para m√©dia igual a zero e desvio padr√£o igual a 1.  
A padroniza√ß√£o dos dados √© uma etapa fundamental em diversos processos de an√°lise estat√≠stica, aprendizado de m√°quina e modelagem preditiva. Ela envolve transformar vari√°veis para que tenham uma escala comum, o que pode ser feito subtraindo a m√©dia e dividindo pelo desvio padr√£o, ou reescalando os valores para uma faixa espec√≠fica, como [0, 1]. A padroniza√ß√£o √© particularmente importante em algoritmos que dependem de medi√ß√µes de dist√¢ncia ou vari√°veis com diferentes escalas.  
Algoritmos que dependem de medi√ß√µes de dist√¢ncia, como KNN (K-vizinhos mais pr√≥ximos) e clustering (K-means, por exemplo), podem ser severamente influenciados por vari√°veis com escalas maiores. Nesse caso, vari√°veis com valores num√©ricos maiores podem influenciar fortemente as dist√¢ncias calculadas, distorcendo os resultados. Padronizar os dados assegura que todas as vari√°veis tenham um impacto compar√°vel nas medidas de dist√¢ncia.  

Agora vamos dividir os dados em treino e teste.  

```{r}
# Separando em treino e test.
n <- nrow(df_p)
set.seed(134) # Para reprodutibilidade dos resultados.
i <- sample(x = c(TRUE, FALSE),
            size = n,
            replace = TRUE,
            prob = c(0.70, 1 - 0.70))

df_train <- df_p[i, ]
print(nrow(df_train))
df_test <- df_p[!i, ]
print(nrow(df_test))
```

Vamos verificar a propor√ß√£o de treino e teste.  
```{r}
# Propor√ß√£o treino e teste
prop <- round(c(nrow(df_train), 
        nrow(df_test))/n, 
      digits = 3)*100
print(prop)
```

Muito pr√≥ximo de 70% para treino e 30% para teste.  

#### Obtendo as predi√ß√µes para o conjunto de teste via conjunto de treino.
- K = 3
```{r}
m0 <- knn(train = df_train[, -6],
          test = df_test[, -6],
          cl = df_train[, 6],
          k = 3)
```

#### Avalia√ß√£o do modelo
```{r}
# Tabela de confus√£o.
ct <- table(df_test[, 6], m0)
# Renomeando as linhas e colunas
rownames(ct) <- c("Alta_V", "M√©dia_V", "Baixa_V")
colnames(ct) <- c("Alta_Prev", "M√©dia_Prev", "Baixa_Prev")
print(ct)
```


```{r}
# Conferindo a Tabela do teste
print(xtabs(~Classe, data = df_test))
```

Visualizando os erros e acertos.  
```{r}
# Juntando a base de teste com a previs√£o
df_comp <- cbind(df_test, Previssao = m0)
df_comp |> 
  gt()
```


#### Acur√°cia do modelo.  
```{r}
# Acur√°ria = Fra√ß√£o de acertos totais.
A <- sum(diag(ct))/sum(ct)*100
print(paste0(round(A, 1), "%"))
```

O modelo obteve uma acur√°cia de `r paste0(round(A, 1), "%")`, ou seja, acertou `r sum(diag(ct))` de `r sum(ct)` observa√ß√µes da base de teste.  


#### Precis√£o, Sensibilidade e F1-Score
Precis√£o, Sensibilidade e F1-Score s√£o √∫teis para cada classe individualmente.


##### Precis√£o = Valor preditivo 
A Precis√£o √© uma m√©trica que indica a propor√ß√£o de previs√µes corretas para uma determinada classe em rela√ß√£o ao total de previs√µes feitas para essa classe. Ou seja, a Precis√£o foca em quantas das previs√µes feitas para uma classe espec√≠fica realmente pertencem √†quela classe. A f√≥rmula para calcular a Precis√£o √©:  

$$P = \frac{TP}{TP + FP}$$
No exemplo em quest√£o temos:  
* Precis√£o para a Classe "Alta":  
Para calcular a precis√£o da classe "alta", olhamos para o n√∫mero de Verdadeiros Positivos e Falsos Positivos:  

*Verdadeiros Positivos (VP)*: S√£o as previs√µes corretas para a classe "Alta". Aqui, temos `r ct[1,1]` sementes corretamente classificadas como "Alta".  
*Falsos Positivos (FP)*: S√£o as sementes previstas como "Alta", mas que na verdade pertencem a outra classe. Nesse caso, temos `r ct[2,1]` sementes da classe "Alta" classificadas como da classe "M√©dia" e `r ct[3,1]` sementes da classe "Alta" classificadas como "Baixa".  
Agora podemos calcular a precis√£o para a classe "Alta":
$$P_i = \frac{TP_i}{TP_i + FP_i}$$  
$$P = \frac{`r ct[1,1]`}{`r ct[1,1]` + `r ct[2,1]` + `r ct[3,1]`}$$  
$$P = \frac{`r ct[1,1]`}{`r sum(ct[,1])`}$$  
$$P = `r ct[1,1]/sum(ct[,1])`$$  
Multiplicando por 100 para obter a porcentagem.  
$$P = `r ct[1,1]/sum(ct[,1])*100`$$  


```{r}
P_alta <- ct[1,1]/sum(ct[,1])
print(paste0(round(P_alta,3)*100, "%"))
```

- De forma an√°loga fazemos para as demais classes.  
```{r}
P_media <- ct[2,2]/sum(ct[,2])
print(paste0(round(P_media,3)*100, "%"))
```

```{r}
P_baixa <- ct[3,3]/sum(ct[,3])
print(paste0(round(P_baixa,3)*100, "%"))
```



#####  Sensibilidade/Recall

A Sensibilidade (tamb√©m chamada de Recall ou Taxa de Verdadeiros Positivos) √© uma m√©trica de avalia√ß√£o de modelos de classifica√ß√£o que indica a capacidade do modelo em identificar corretamente as inst√¢ncias de uma classe espec√≠fica. Em outras palavras, ela nos diz o qu√£o bem o modelo consegue capturar todos os exemplos de uma classe.

A f√≥rmula para a Sensibilidade para uma classe $C_i$ √© dada por:
$$Sensibilidade_{C_i} = \frac{TP_i}{TP_i + FN_i} $$
Onde:
- $TP_i$ √© o n√∫mero de verdadeiros positivos para a classe $C_i$;
- $FN_i$ √© o n√∫mero de falsos negativos para a classe $C_i$, ou seja, quando o modelo classifica erradamente exemplos da classe $C_i$ como sendo de outra classe.  
No exemplo em quest√£o temos:  

* Para a classe "Alta":  
$$Sensibilidade_{Alta} = \frac{TP_{Alta}}{TP_{Alta} + FN_{Alta}}$$  
$$Sensibilidade_{Alta} = \frac{`r ct[1,1]`}{`r ct[1,1]` + (`r ct[1,2]` + `r ct[1,3]`)} $$  
$$Sensibilidade_{Alta} = \frac{`r ct[1,1]`}{`r ct[1,1]` + `r ct[1,2] + ct[1,3]`}$$  
$$Sensibilidade_{Alta} = \frac{`r ct[1,1]`}{`r sum(ct[1,])`}$$  
$$Sensibilidade_{Alta} = `r ct[1,1]/sum(ct[1,])`$$  
Multiplicando por 100 para obter a porcentagem.  
$$Sensibilidade_{Alta} = `r ct[1,1]/sum(ct[1,])*100`$$  

No R temos para a classe "Alta":   
```{r}
S_alta <- ct[1,1]/sum(ct[1,])
print(paste0(round(S_alta,3)*100, "%"))
```

Para a classe "M√©dia":  
```{r}
S_media <- ct[2,2]/sum(ct[2,])
print(paste0(round(S_media,3)*100, "%"))
```

Para a classe "Baixa":  
```{r}
S_baixa <- ct[3,3]/sum(ct[3,])
print(paste0(round(S_baixa,3)*100, "%"))
```

A Sensibilidade √© uma m√©trica importante quando queremos minimizar o n√∫mero de falsos negativos, ou seja, quando √© crucial que o modelo identifique o m√°ximo poss√≠vel de exemplos de uma determinada classe. Isso √© especialmente importante em situa√ß√µes onde falhas na detec√ß√£o podem ser custosas, como em diagn√≥sticos m√©dicos ou controle de qualidade no agroneg√≥cio.  
No exemplo de diagn√≥sticos de qualidade no agroneg√≥cio, vamos imaginar a seguinte situa√ß√£o: um modelo de classifica√ß√£o √© utilizado para identificar doen√ßas em plantas, se o modelo tiver uma baixa Sensibilidade, ele pode deixar de detectar plantas doentes, o que pode levar a uma propaga√ß√£o da doen√ßa e preju√≠zos para o produtor. Portanto, a Sensibilidade √© uma m√©trica importante para avaliar a capacidade do modelo em identificar corretamente os casos positivos de doen√ßas.    

##### F1-Score = M√©dia harm√¥nica entre precis√£o e Sensibilidade 

O `F1-Score` √© uma m√©trica que combina a `Precis√£o` e a `Sensibilidade (Recall)` em uma √∫nica m√©trica, oferecendo um equil√≠brio entre elas. √â especialmente √∫til quando existe um desequil√≠brio entre as classes, pois considera tanto os falsos positivos quanto os falsos negativos. O F1-Score √© a m√©dia harm√¥nica entre a Precis√£o e a Sensibilidade, garantindo que ambos os aspectos sejam igualmente ponderados.  

F√≥rmula do F1-Score:  
$$F1 = 2 \times \frac{Precis√£o \times Sensibilidade}{Precis√£o + Sensibilidade}$$

No exemplo em quest√£o temos:
* Para a classe "Alta":  

$$F1_{Alta} = 2 \times \frac{Precis√£o_{Alta} \times Sensibilidade_{Alta}}{Precis√£o_{Alta} + Sensibilidade_{Alta}}$$

No R temos:  
```{r}
F1_alta <- 2*((P_alta*S_alta)/(P_alta+S_alta))
print(paste0(round(F1_alta,3)*100, "%"))
```

Para as demais classes temos:  
```{r}
F1_media <- 2*((P_media*S_media)/(P_media+S_media))
print(paste0(round(F1_media,3)*100, "%"))
```

```{r}
F1_baixa <- 2*((P_baixa*S_baixa)/(P_baixa+S_baixa))
print(paste0(round(F1_baixa,3)*100, "%"))
```


#### Especificidade.

A Especificidade (tamb√©m chamada de Taxa de Verdadeiros Negativos, ou True Negative Rate) √© uma m√©trica que avalia a propor√ß√£o de negativos verdadeiros corretamente identificados pelo modelo em rela√ß√£o ao total de exemplos que realmente s√£o negativos. Em outras palavras, a Especificidade mede a capacidade do modelo de n√£o classificar falsamente os negativos como positivos.

F√≥rmula da Especificidade:
$$Especificidade = \frac{TN}{TN + FP}$$  
Onde:
- $TN$ √© o n√∫mero de verdadeiros negativos;
- $FP$ √© o n√∫mero de falsos positivos.

No exemplo em quest√£o temos:
* Para a classe "Alta":
- $TN$ √© o n√∫mero de verdadeiros negativos para a classe "Alta". Aqui, temos `r sum(c(ct[2,2], ct[3,3]))` sementes corretamente classificadas como "M√©dia" e "Baixa", que s√£o as sementes que realmente n√£o t√™m qualidade "Alta" e foram corretamente classificadas como n√£o sendo "Alta".  
- $FP$ √© o n√∫mero de falsos positivos para a classe "Alta". Aqui, temos `r ct[2,1]` e `r ct[3,1]` sementes "M√©dia" e "Baixa" incorretamente previstas como "Alta".  

$$Especificidade_{Alta} = \frac{TN_{Alta}}{TN_{Alta} + FP_{Alta}}$$  


No R temos:  
```{r}
E_alta <- sum(c(ct[2,2], ct[3,3]))/(sum(c(ct[2,2], ct[3,3]))+sum(ct[2:3,1]))
print(paste0(round(E_alta,3)*100, "%"))
```

Para as demais classes temos:  

```{r}
E_media <- sum(c(ct[1,1],ct[3,3]))/(sum(c(ct[1,1],ct[3,3]))+sum(ct[c(1,3),2]))
print(paste0(round(E_media,3)*100, "%"))
```

```{r}
E_baixa <- sum(c(ct[1,1],ct[2,2]))/(sum(c(ct[1,1],ct[2,2]))+sum(ct[1:2,3]))
print(paste0(round(E_baixa,3)*100, "%"))
```

#### Curva ROC

A curva ROC (Receiver Operating Characteristic) √© uma ferramenta gr√°fica que nos ajuda a avaliar a capacidade de um modelo de classifica√ß√£o bin√°ria em distinguir entre duas classes. A curva ROC √© constru√≠da plotando a Taxa de Verdadeiros Positivos (Sensibilidade) no eixo y e a Taxa de Falsos Positivos (1 - Especificidade) no eixo x.  

Um valor de ROC de 0,5 indica um desempenho aleat√≥rio, enquanto um valor de 1 indica um desempenho perfeito, como podemos ver nas imagens abaixo.  
![Compara√ß√£o de desempenhos da curva ROC](images/roc_curva.png)
  
Desta forma, quanto maior a ROC, melhor o modelo est√° em separar as classes.  

Para calcular a Curva ROC em um problema de classifica√ß√£o com tr√™s categorias ("Alta", "M√©dia" e "Baixa"), √© necess√°rio transformar o problema de m√∫ltiplas classes em um problema bin√°rio para cada uma das classes. Isso √© feito atrav√©s da abordagem One-vs-Rest (Um contra Todos). Para cada classe, voc√™ calcula uma curva ROC considerando aquela classe como a positiva, e as demais como negativas.  

Para cada classe, criamos um classificador bin√°rio, calculando a matriz de confus√£o para cada classe:  

- Matriz de confus√£o para a classe "Alta":  
```{r}
ct_alta <- matrix(c(ct[1,1], sum(ct[1,2:3]), 
                    sum(ct[2:3,1]), sum(ct[2:3,2:3])), 
                  ncol = 2, byrow = TRUE)
print(ct_alta)
# Nomeando as linhas e colunas da matriz
rownames(ct_alta) <- c("Real: Alta", "Real: Outras")
colnames(ct_alta) <- c("Previsto: Alta", "Previsto: Outras")
print(ct_alta)
```

- Plotar a Curva ROC em R
```{r}
# install.packages("pROC")
library(pROC)
# Classes reais (1 para "Alta", 0 para "Outros")
# xtabs(~Classe, data = df_test)
real_valores <- ifelse(df_test$Classe == 'alta', 1, 0) # 24 reais "Alta" e 37 "Outros"
print(length(real_valores))
# Previs√µes do classificador (1 para "Alta", 0 para "Outros")
predicted_values <- c(rep(1, 21), rep(0, 21), rep(0, 19)) 
print(length(predicted_values))
# Calcular a curva ROC
roc_curve <- roc(real_valores, predicted_values)

# Exibir os resultados da curva ROC
print(roc_curve)

# Plotar a curva ROC
plot(roc_curve, col = "blue", lwd = 2, main = "Curva ROC - Classe 'Alta'")

# AUC
print(auc(roc_curve))
```

Interpreta√ß√£o Gr√°fica da Curva ROC:  
O gr√°fico da curva ROC mostrar√° o desempenho do seu classificador ao variar o limiar de decis√£o.  
O ponto mais √† esquerda e no topo (TPR = 1 e FPR = 0) representa o classificador ideal.  
A AUC (√Årea Sob a Curva) quantifica o desempenho do classificador. Quanto mais pr√≥ximo de 1, melhor √© o desempenho do classificador.  


### M√©tricas de Avalia√ß√£o de Classificadores: Quando e Como Utiliz√°-las Eficazmente
A avalia√ß√£o de classificadores por meio de medidas como acur√°cia, precis√£o, sensibilidade (ou recall), F1-score, especificidade, curva ROC e coeficiente Kappa depende do tipo de problema e dos objetivos da aplica√ß√£o. A seguir, comento quando cada uma dessas medidas √© mais adequada:  

**Acur√°cia**: Mede a propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de previs√µes. √â √∫til quando as classes est√£o bem balanceadas. No entanto, pode ser enganosa em problemas de classes desbalanceadas, onde uma classe majorit√°ria pode ser corretamente classificada na maior parte do tempo, distorcendo a avalia√ß√£o.  

Quando usar: Quando h√° balanceamento entre as classes ou quando o erro em classes minorit√°rias n√£o √© cr√≠tico.  

**Precis√£o**: Avalia a propor√ß√£o de previs√µes positivas corretas em rela√ß√£o ao total de previs√µes positivas feitas pelo modelo. √â relevante quando o custo de falsos positivos √© alto.  

Quando usar: Em cen√°rios onde √© mais importante evitar falsos positivos, como em detec√ß√£o de fraudes financeiras.  

**Sensibilidade (Recall)**: Mede a propor√ß√£o de verdadeiros positivos corretamente identificados em rela√ß√£o ao total de positivos reais. √â importante em situa√ß√µes onde a prioridade √© identificar a maior quantidade poss√≠vel de verdadeiros positivos.  

Quando usar: Em problemas onde falsos negativos s√£o mais custosos, como na detec√ß√£o de doen√ßas (ex.: diagn√≥stico m√©dico).  

**F1-score**: Combina precis√£o e sensibilidade em uma m√©dia harm√¥nica. √â √∫til quando h√° um trade-off entre esses dois indicadores, sendo uma m√©trica adequada para cen√°rios desbalanceados.  

Quando usar: Quando h√° um desbalanceamento nas classes e tanto falsos positivos quanto falsos negativos s√£o igualmente importantes.  

**Especificidade**: Mede a propor√ß√£o de negativos reais que foram corretamente identificados, ou seja, a capacidade do classificador em evitar falsos positivos.  

Quando usar: Quando √© importante minimizar falsos positivos, como em testes de doen√ßas raras (evitar diagn√≥sticos errados).  

**Curva ROC e AUC**: A curva ROC mostra a rela√ß√£o entre a sensibilidade e a especificidade em diferentes limiares de classifica√ß√£o. A m√©trica AUC (√Årea sob a curva) quantifica a capacidade do modelo de discriminar entre as classes.  

Quando usar: Em problemas com desbalanceamento ou quando voc√™ quer comparar o desempenho do classificador ao longo de diferentes limiares de decis√£o.  

**Coeficiente Kappa**: Avalia a concord√¢ncia entre as previs√µes do modelo e os valores reais, considerando o acaso. √â particularmente √∫til quando voc√™ quer medir o grau de concord√¢ncia do modelo al√©m do que seria esperado aleatoriamente.  

Quando usar: Quando voc√™ precisa avaliar a concord√¢ncia em problemas multiclasses ou quando a acur√°cia pode ser distorcida por chance.  

Essas medidas devem ser escolhidas com base nos objetivos do problema de classifica√ß√£o e no impacto relativo dos diferentes tipos de erros. 


### Comparar diferentes k's
Vamos considerar o crit√©rio da Acu√°ria para escolher o melhor valor de $k$, fazendo o ajuste do modelo para diferentes valores de $k$ e comparando a acur√°cia obtida.  
```{r}
# cria uma lista para receber as predicoes
Knn_Testes = list()

# cria variavel para receber acuracia
acuracia = numeric()

# cria loop para testar de k=1 ate k=20
for(k in 1:20){
Knn_Testes[[k]] = knn(train = df_train[,-6], 
                      df_test[,-6], 
                      cl = df_train[,6], 
                      k)
acuracia[k] = sum(Knn_Testes[[k]]==df_test[,6])/length(df_test[,6])*100
}
print(acuracia)
```

Verificando graficmente
```{r}
# Comparacao grafica das acuracias
# Criando um data frame com os dados de k e acuracia
dt <- data.frame(k = 1:k, acuracia = acuracia)

# Gerando o gr√°fico
acurac <- dt |> 
      ggplot(aes(x = k,
                 y = acuracia)) +
  geom_line(color = "blue") +       # Linha azul
  geom_point(color = "blue", size = 3) +  # Pontos azuis
  labs(title = "Acur√°cia para cada k", 
       x = "k", 
       y = "Acur√°cia") +
  theme_minimal()
print(acurac)
```

Observemos que a acur√°cia √© maior para o valor de $k = 11$. Portanto, o melhor valor de $k$ para este problema √© 11. Podemos ent√£o colocar o modelo definitivo com $k = 11$ em produ√ß√£o.  


#### Previs√£o da classe para novos valores
Vamos considerar um novo conjunto com cinco novas amostras de solo para prever a classe de qualidade de sementes esperada.  
```{r}
# Novos valores
novos_valores <- data.frame(pH = c(4.2, 7.4, 5.7, 5.8, 6.9),
                            MO = c(1.5, 3.6, 2.7, 4.8, 3.9),
                            P = c(18.5, 13.6, 22.7, 18.8, 35.9),
                            K = c(26.5, 28.6, 26.7, 30.8, 37.9),
                            Arg = c(17.5, 20.6, 30.7, 40.8, 41.9))
print(novos_valores)
```

Com os valores est√£o em escalas diferentes √© necess√°rio a transforma√ß√£o de escala para uma padronizada. Vamos ent√£o escalonar os novos valores, para m√©dia igual a zero e desvio padr√£o igual a 1 em rela√ß√£o aos dados da base original.       
```{r}
# calculando as m√©dias e desvios padr√£o de cada vari√°vel
medias <- colMeans(df[,1:5])
desv_pad <- apply(df[,1:5], 2, sd)

# padronizando os novos valores em rela√ß√£o aos dados da base original
novos_valores_p <- scale(novos_valores, 
                         center = medias, 
                         scale = desv_pad)
print(novos_valores_p)
```

Como valor do $K$ j√° foi otimizado, vamos considerar o valor de $k = 11$ para prever a classe dos novos valores. No entanto, podemos utilizar todos os dados dispon√≠veis para treinar o modelo, j√° que o modelos j√° foi validado e o par√¢metro $K$ otimizado.    

Utilizando o valor de $k = 11$ para prever a classe dos novos valores.  
```{r}
Knn_K11_Predicao = knn(train = df_p[,-6], 
                       test = novos_valores_p,
                       cl = df_p[, 6], 
                       k = 11)
print(Knn_K11_Predicao)
```

Agora temos a previs√£o da classe para os novos valores.

## Conclus√£o
Neste tutorial, aprendemos a usar a classifica√ß√£o `K-Nearest Neighbors (KNN)` com o R. Abordamos o conceito b√°sico de KNN e como ele funciona. Em seguida, aplicamos o algoritmo KNN a um conjunto de dados de exemplo para classificar sementes de soja com base em suas caracter√≠sticas de solo.   
Voc√™ precisa entender que o algoritmo KNN n√£o √© perfeito, ele tamb√©m tem algumas desvantagens, e √© preciso levar em conta v√°rios aspectos antes de selecion√°-lo como modelo principal.  